{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q0h5Lhdc8pCj"
   },
   "source": [
    "# Semantic Segmentation with FastSCNN - changing input dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3B_C0udn81Wl"
   },
   "source": [
    "The purpose of this model is to train the network on the train dataset and then export the model in onnx format and also save the state_dict of the pytorch model for later inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Do not run this cell outside of Google Colaboratory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MsUVejuD8NE4",
    "outputId": "259b9f11-9def-482c-aaff-65b76d14c9ff"
   },
   "outputs": [],
   "source": [
    "!pip3 install -q -U albumentations\n",
    "!echo \"$(pip freeze | grep albumentations) is successfully installed\"\n",
    "!pip uninstall opencv-python-headless==4.5.5.62\n",
    "!pip install opencv-python-headless==4.5.2.52\n",
    "!pip install torchmetrics\n",
    "!pip install torch==1.8.0+cu111 torchvision==0.9.0+cu111 torchaudio==0.8.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "!git clone https://github.com/xolotl18/Master_Thesis\n",
    "!pip install onnx\n",
    "!pip install onnxruntime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ToEHpxrS9YrK"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "DNzYJzDG8oTS"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "import albumentations as A\n",
    "import albumentations.augmentations.functional as F\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchmetrics import JaccardIndex\n",
    "from statistics import mean\n",
    "import torchvision.transforms as T\n",
    "import torch.onnx\n",
    "import onnx\n",
    "import onnxruntime\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "from utils.lr_scheduler import PolynomialLRDecay\n",
    "from models.experiments.fast_scnn_mod import FastSCNN as fastscnn_mod\n",
    "\n",
    "from utils.dataset import PackagesDataset, PackagesInferenceDataset\n",
    "from utils.evaluation import Evaluate\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "DeDfSTgaFytR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The device is : cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "params = {\n",
    "    \"device\" : device,\n",
    "    \"lr\" : 0.01,\n",
    "    \"batch_size\" : 8,\n",
    "    \"num_workers\" : 4,\n",
    "    \"epochs\" : 400,\n",
    "}\n",
    "print(f\"The device is : {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "GeVIeZ9GDdu9"
   },
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, scheduler, epoch, params):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 1):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        images, targets = data\n",
    "        images = images.to(params[\"device\"], non_blocking=True)\n",
    "        targets = targets.to(params[\"device\"], non_blocking=True)\n",
    "\n",
    "        outputs = model(images)\n",
    "        targets = torch.unsqueeze(targets, 1)\n",
    "\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step(epoch)\n",
    "        running_loss += loss.item()*images.size(0)\n",
    "\n",
    "def validate(val_loader, model, criterion, epoch, params):\n",
    "    model.eval()\n",
    "    running_loss=0.0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(val_loader, start=1):\n",
    "                images, targets = data\n",
    "                images = images.to(params[\"device\"], non_blocking=True)\n",
    "                targets = targets.to(params[\"device\"], non_blocking=True)\n",
    "                output = model(images).squeeze(1)\n",
    "                loss = criterion(output, targets)\n",
    "                running_loss += loss.item()*images.size(0)\n",
    "    return running_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, params, test_dataset):\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, batch_size=params[\"batch_size\"], shuffle=False, num_workers=params[\"num_workers\"], pin_memory=True,\n",
    "    )\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for images, masks, (original_heights, original_widths) in test_loader:\n",
    "            images = images.to(params[\"device\"], non_blocking=True)\n",
    "            output = model(images)\n",
    "            probabilities = torch.sigmoid(output.squeeze(1))\n",
    "            predicted_masks = (probabilities >= 0.5).float() * 1\n",
    "            predicted_masks = predicted_masks.cpu().numpy()\n",
    "            for predicted_mask, gt, original_height, original_width in zip(\n",
    "                predicted_masks, masks.numpy(), original_heights.numpy(), original_widths.numpy()\n",
    "            ):\n",
    "                predictions.append((predicted_mask, gt, original_height, original_width))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_initializer_from_input(model_path):\n",
    "\n",
    "    onnxmodel = onnx.load(model_path+\".onnx\")\n",
    "    if onnxmodel.ir_version < 4:\n",
    "        print(\"Model with ir_version below 4 requires to include initilizer in graph input\")\n",
    "        return\n",
    "\n",
    "    inputs = onnxmodel.graph.input\n",
    "    name_to_input = {}\n",
    "    for input in inputs:\n",
    "        name_to_input[input.name] = input\n",
    "\n",
    "    for initializer in onnxmodel.graph.initializer:\n",
    "        if initializer.name in name_to_input:\n",
    "            inputs.remove(name_to_input[initializer.name])\n",
    "    out_path = model_path+\"_noinit.onnx\"\n",
    "    onnx.save(onnxmodel, out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ly8xqG0BpMa"
   },
   "source": [
    "## Load image and label files into Dataset objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o8zTRzUcB26B"
   },
   "source": [
    "The dataset has already been divided into train, validation and test folders in the notebook **Desktop/Master_Thesis/preparation/dataset_traintest_split.ipynb**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ht_TfMCX_YPU",
    "outputId": "90574f95-389a-4d0e-b9bb-087f6ee935ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the train set is : 300\n",
      "\n",
      "The size of the validation set is : 40\n",
      "\n",
      "The size of the test set is : 60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "c_dir = os.getcwd()\n",
    "dataset_directory = os.path.join(c_dir, \"full_dataset\")\n",
    "\n",
    "train_images_directory = os.path.join(dataset_directory, \"train/images\")\n",
    "train_masks_directory = os.path.join(dataset_directory, \"train/labels\")\n",
    "val_images_directory = os.path.join(dataset_directory, \"val/images\")\n",
    "val_masks_directory = os.path.join(dataset_directory, \"val/labels\")\n",
    "test_images_directory = os.path.join(dataset_directory, \"test/images\")\n",
    "test_masks_directory = os.path.join(dataset_directory, \"test/labels\")\n",
    "\n",
    "#make sure that image_filenames only contains png files\n",
    "train_images_filenames = []\n",
    "train_images_filenames = [ item for item in os.listdir(train_images_directory) if item.endswith(\".png\") ]\n",
    "val_images_filenames = []\n",
    "val_images_filenames = [ item for item in os.listdir(val_images_directory) if item.endswith(\".png\") ]\n",
    "test_images_filenames = []\n",
    "test_images_filenames = [ item for item in os.listdir(test_images_directory) if item.endswith(\".png\") ]\n",
    "\n",
    "for names_list, split in zip((train_images_filenames, val_images_filenames, test_images_filenames), ('train', 'validation', 'test')):\n",
    "  print(f\"The size of the {split} set is : {len(names_list)}\")\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension_multipliers =[1.0, 0.5, 0.4375, 0.375, 0.3125, 0.25, 0.1875]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input of dimension 512x512x3\n",
      "\n",
      "The model has been initialized with parameters:\n",
      "\t Width multiplier a =  1.0\n",
      "\t Bottleneck expansion rate t =  6\n",
      "\t Bottleneck block repetition r =  3\n",
      "\t Presence of Pyramid Pooling module pp =  0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a21927dd4e54f4d9acd673ca7e8d196",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Intersection over Union score is : 0.9775\n",
      "The Dice Coefficient is : 0.9886\n",
      "Onnx model saved\n",
      "\n",
      "\n",
      "Input of dimension 256x256x3\n",
      "\n",
      "The model has been initialized with parameters:\n",
      "\t Width multiplier a =  1.0\n",
      "\t Bottleneck expansion rate t =  6\n",
      "\t Bottleneck block repetition r =  3\n",
      "\t Presence of Pyramid Pooling module pp =  0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c7029ea026a4500b581235c3aebfca9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Intersection over Union score is : 0.9706\n",
      "The Dice Coefficient is : 0.9851\n",
      "Onnx model saved\n",
      "\n",
      "\n",
      "Input of dimension 224x224x3\n",
      "\n",
      "The model has been initialized with parameters:\n",
      "\t Width multiplier a =  1.0\n",
      "\t Bottleneck expansion rate t =  6\n",
      "\t Bottleneck block repetition r =  3\n",
      "\t Presence of Pyramid Pooling module pp =  0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11a0308e49b7414f9827e686195a6132",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Intersection over Union score is : 0.9675\n",
      "The Dice Coefficient is : 0.9835\n",
      "Onnx model saved\n",
      "\n",
      "\n",
      "Input of dimension 192x192x3\n",
      "\n",
      "The model has been initialized with parameters:\n",
      "\t Width multiplier a =  1.0\n",
      "\t Bottleneck expansion rate t =  6\n",
      "\t Bottleneck block repetition r =  3\n",
      "\t Presence of Pyramid Pooling module pp =  0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24505e0eb60c42cbbbae884db81dde60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Intersection over Union score is : 0.9703\n",
      "The Dice Coefficient is : 0.9849\n",
      "Onnx model saved\n",
      "\n",
      "\n",
      "Input of dimension 160x160x3\n",
      "\n",
      "The model has been initialized with parameters:\n",
      "\t Width multiplier a =  1.0\n",
      "\t Bottleneck expansion rate t =  6\n",
      "\t Bottleneck block repetition r =  3\n",
      "\t Presence of Pyramid Pooling module pp =  0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "205c77a6d2114e31b8268c2e2f0d18ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Intersection over Union score is : 0.9621\n",
      "The Dice Coefficient is : 0.9807\n",
      "Onnx model saved\n",
      "\n",
      "\n",
      "Input of dimension 128x128x3\n",
      "\n",
      "The model has been initialized with parameters:\n",
      "\t Width multiplier a =  1.0\n",
      "\t Bottleneck expansion rate t =  6\n",
      "\t Bottleneck block repetition r =  3\n",
      "\t Presence of Pyramid Pooling module pp =  0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94c3dd6e985147b9be5285d8a4e9d90e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Intersection over Union score is : 0.9537\n",
      "The Dice Coefficient is : 0.9763\n",
      "Onnx model saved\n",
      "\n",
      "\n",
      "Input of dimension 96x96x3\n",
      "\n",
      "The model has been initialized with parameters:\n",
      "\t Width multiplier a =  1.0\n",
      "\t Bottleneck expansion rate t =  6\n",
      "\t Bottleneck block repetition r =  3\n",
      "\t Presence of Pyramid Pooling module pp =  0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da5381205aa8410eb1eeddadd495aaa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Intersection over Union score is : 0.9357\n",
      "The Dice Coefficient is : 0.9667\n",
      "Onnx model saved\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for m in dimension_multipliers:\n",
    "    train_transform = A.Compose(\n",
    "        [\n",
    "            A.Resize(int(m*540), int(m*960)),\n",
    "            A.RandomCrop(int(m*512), int(m*512)),\n",
    "            A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=0.5),\n",
    "            A.RGBShift(r_shift_limit=15, g_shift_limit=15, b_shift_limit=15, p=0.3),\n",
    "            A.RandomBrightnessContrast(p=0.3),\n",
    "            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "            ToTensorV2(),\n",
    "        ]\n",
    "    )\n",
    "    val_transform = A.Compose(\n",
    "        [\n",
    "            A.Resize(int(m*540), int(m*960)),\n",
    "            A.CenterCrop(int(m*512), int(m*512)),\n",
    "            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "            ToTensorV2(),\n",
    "        ]\n",
    "    )\n",
    "    test_transform = A.Compose(\n",
    "        [\n",
    "            A.Resize(int(m*512), int(m*512)),\n",
    "            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "            ToTensorV2(),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    train_dataset = PackagesDataset(train_images_filenames, train_images_directory, \n",
    "                                    train_masks_directory, transform=train_transform,)\n",
    "    val_dataset = PackagesDataset(val_images_filenames, val_images_directory,\n",
    "                                  val_masks_directory, transform=val_transform,)\n",
    "    test_dataset = PackagesInferenceDataset(test_images_filenames, test_images_directory, \n",
    "                                            test_masks_directory, transform=test_transform,)\n",
    "    input_sample = train_dataset[0][0].numpy()\n",
    "    chans, dim1, dim2 = input_sample.shape\n",
    "    print()\n",
    "    print(f\"Input of dimension {dim1}x{dim2}x{chans}\")\n",
    "    print()\n",
    "    #we run the baseline model without pyramid pooling since we have affirmed that its effect is \n",
    "    #irrelevant on the dataset in use and it causes issues when varying input size\n",
    "    model = fastscnn_mod(in_channels=3, num_classes=1, a=1.0, t=6, r=3, pp=False).to(params[\"device\"])\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=params[\"batch_size\"],\n",
    "    shuffle=True,\n",
    "    num_workers=params[\"num_workers\"],\n",
    "    pin_memory=False,\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=params[\"batch_size\"],\n",
    "        shuffle=True,\n",
    "        num_workers=params[\"num_workers\"],\n",
    "        pin_memory=False,\n",
    "    )\n",
    "\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=params[\"lr\"])\n",
    "    scheduler = PolynomialLRDecay(optimizer, max_decay_steps=params[\"epochs\"], end_learning_rate=0.0001, power=0.9)\n",
    "\n",
    "    best_loss = sys.float_info.max\n",
    "    model_ckpt = copy.deepcopy(model.state_dict())\n",
    "    for epoch in tqdm(range(1, params[\"epochs\"]+1)):\n",
    "        train(train_loader, model, criterion, optimizer, scheduler, epoch, params)\n",
    "        epoch_loss = validate(val_loader, model, criterion, epoch, params)\n",
    "        #select the best model based on the loss on the validation set\n",
    "        if epoch_loss < best_loss:\n",
    "            best_loss = epoch_loss\n",
    "            model_ckpt = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    model.load_state_dict(model_ckpt)    \n",
    "    predictions = predict(model, params, test_dataset)\n",
    "\n",
    "    evaluator = Evaluate(predictions)\n",
    "    iou, dice = evaluator.get_metrics().values()\n",
    "    print(f\"The Intersection over Union score is : {iou:.4f}\")\n",
    "    print(f\"The Dice Coefficient is : {dice:.4f}\")\n",
    "    \n",
    "    #select the name that the model will be saved with\n",
    "    model_name = \"fastscnn_\"+str(dim1)\n",
    "    model_path = os.path.join(c_dir, \"model_checkpoints/experiments/input_dim\", model_name)\n",
    "    torch.save(model.state_dict(), model_path+\".pt\")\n",
    "    \n",
    "    #put the model in inference mode\n",
    "    model.eval()\n",
    "    #generate dummy input for onnx export\n",
    "    x = torch.randn(1, 3, int(m*512), int(m*512), requires_grad=True).cuda()\n",
    "    torch_out = model(x)\n",
    "\n",
    "    # Export the model\n",
    "    torch.onnx.export(model,                         # model being run\n",
    "                      x,                             # model input (or a tuple for multiple inputs)\n",
    "                      model_path+\".onnx\",            # where to save the model (can be a file or file-like object)\n",
    "                      export_params=True,            # store the trained parameter weights inside the model file\n",
    "                      opset_version=11,              # the ONNX version to export the model to\n",
    "                      do_constant_folding=True,      # whether to execute constant folding for optimization\n",
    "                      input_names = ['input'],       # the model's input names\n",
    "                      output_names = ['output'],     # the model's output names\n",
    "                      operator_export_type=torch.onnx.OperatorExportTypes.ONNX,\n",
    "                      dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
    "                                    'output' : {0 : 'batch_size'}})\n",
    "    remove_initializer_from_input(model_path)\n",
    "    print(\"Onnx model saved\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOUbNM9vv8a2lLIS9oTCmUR",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
