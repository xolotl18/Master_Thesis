{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e7d25f4-702f-43b8-b066-2537e9297442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n",
      "fastscnn_96a1.0t6r1pp0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:07<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The mean latency in onnx  is: 0.0003294221560160319\n",
      "\n",
      "The mean iou of onnx  model is:  0.9386850971702091\n",
      "\n",
      "96\n",
      "fastscnn_96a0.25t6r3pp0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:07<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The mean latency in onnx  is: 0.00032519976298014323\n",
      "\n",
      "The mean iou of onnx  model is:  0.925940248764397\n",
      "\n",
      "96\n",
      "fastscnn_96a0.25t6r1pp0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:07<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The mean latency in onnx  is: 0.0001980133851369222\n",
      "\n",
      "The mean iou of onnx  model is:  0.9101568293310298\n",
      "\n",
      "96\n",
      "fastscnn_96a0.25t2r3pp0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:06<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The mean latency in onnx  is: 0.00028613964716593427\n",
      "\n",
      "The mean iou of onnx  model is:  0.9282532092293517\n",
      "\n",
      "96\n",
      "fastscnn_96a0.125t6r2pp0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:06<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The mean latency in onnx  is: 0.0002564255396525065\n",
      "\n",
      "The mean iou of onnx  model is:  0.9052762092560597\n",
      "\n",
      "96\n",
      "fastscnn_96a0.125t4r2pp0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:07<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The mean latency in onnx  is: 0.0002353970209757487\n",
      "\n",
      "The mean iou of onnx  model is:  0.9050644515067625\n",
      "\n",
      "96\n",
      "fastscnn_96a0.125t2r2pp0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:06<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The mean latency in onnx  is: 0.0002455576260884603\n",
      "\n",
      "The mean iou of onnx  model is:  0.9026884882933385\n",
      "\n",
      "96\n",
      "fastscnn_96a0.125t2r1pp0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:06<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The mean latency in onnx  is: 0.0002008060614267985\n",
      "\n",
      "The mean iou of onnx  model is:  0.9053740754762065\n",
      "\n",
      "512\n",
      "fastscnn_512a1.0t6r1pp0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:11<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The mean latency in onnx  is: 0.004736454884211223\n",
      "\n",
      "The mean iou of onnx  model is:  0.9788679010340986\n",
      "\n",
      "512\n",
      "fastscnn_512a0.25t6r3pp0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:10<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The mean latency in onnx  is: 0.0023301362991333006\n",
      "\n",
      "The mean iou of onnx  model is:  0.972405903155863\n",
      "\n",
      "512\n",
      "fastscnn_512a0.25t6r1pp0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The mean latency in onnx  is: 0.001967775821685791\n",
      "\n",
      "The mean iou of onnx  model is:  0.9733046264170433\n",
      "\n",
      "512\n",
      "fastscnn_512a0.25t2r3pp0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:10<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The mean latency in onnx  is: 0.0024847896893819173\n",
      "\n",
      "The mean iou of onnx  model is:  0.9779580856690452\n",
      "\n",
      "512\n",
      "fastscnn_512a0.125t6r2pp0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:10<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The mean latency in onnx  is: 0.002170058886210124\n",
      "\n",
      "The mean iou of onnx  model is:  0.9678807359521897\n",
      "\n",
      "512\n",
      "fastscnn_512a0.125t4r2pp0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:10<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The mean latency in onnx  is: 0.0020151448249816893\n",
      "\n",
      "The mean iou of onnx  model is:  0.9716536393088006\n",
      "\n",
      "512\n",
      "fastscnn_512a0.125t2r2pp0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The mean latency in onnx  is: 0.0018515137831370035\n",
      "\n",
      "The mean iou of onnx  model is:  0.9702688831204842\n",
      "\n",
      "512\n",
      "fastscnn_512a0.125t2r1pp0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The mean latency in onnx  is: 0.0018809696038564047\n",
      "\n",
      "The mean iou of onnx  model is:  0.9650866948959712\n",
      "\n",
      "256\n",
      "fastscnn_256a1.0t6r1pp0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:07<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The mean latency in onnx  is: 0.0010973254839579264\n",
      "\n",
      "The mean iou of onnx  model is:  0.971102194017661\n",
      "\n",
      "256\n",
      "fastscnn_256a0.25t6r3pp0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:08<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The mean latency in onnx  is: 0.0007001074155171712\n",
      "\n",
      "The mean iou of onnx  model is:  0.9629473937945364\n",
      "\n",
      "256\n",
      "fastscnn_256a0.25t6r1pp0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:08<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The mean latency in onnx  is: 0.0005398142337799072\n",
      "\n",
      "The mean iou of onnx  model is:  0.9636340572000199\n",
      "\n",
      "256\n",
      "fastscnn_256a0.25t2r3pp0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:08<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The mean latency in onnx  is: 0.000576778252919515\n",
      "\n",
      "The mean iou of onnx  model is:  0.959142296613006\n",
      "\n",
      "256\n",
      "fastscnn_256a0.125t6r2pp0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:07<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The mean latency in onnx  is: 0.0005105714003245036\n",
      "\n",
      "The mean iou of onnx  model is:  0.961317624997109\n",
      "\n",
      "256\n",
      "fastscnn_256a0.125t4r2pp0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:07<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The mean latency in onnx  is: 0.0004949756463368734\n",
      "\n",
      "The mean iou of onnx  model is:  0.9524127540362575\n",
      "\n",
      "256\n",
      "fastscnn_256a0.125t2r2pp0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:07<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The mean latency in onnx  is: 0.0005100961526234945\n",
      "\n",
      "The mean iou of onnx  model is:  0.9540543086865234\n",
      "\n",
      "256\n",
      "fastscnn_256a0.125t2r1pp0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:07<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The mean latency in onnx  is: 0.0004650115966796875\n",
      "\n",
      "The mean iou of onnx  model is:  0.9390962947749107\n",
      "\n",
      "192\n",
      "fastscnn_192a1.0t6r1pp0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:08<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The mean latency in onnx  is: 0.0008239169915517171\n",
      "\n",
      "The mean iou of onnx  model is:  0.9703222633879638\n",
      "\n",
      "192\n",
      "fastscnn_192a0.25t6r3pp0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:07<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The mean latency in onnx  is: 0.0004612894852956136\n",
      "\n",
      "The mean iou of onnx  model is:  0.9569362449909568\n",
      "\n",
      "192\n",
      "fastscnn_192a0.25t6r1pp0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:07<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The mean latency in onnx  is: 0.0003539717197418213\n",
      "\n",
      "The mean iou of onnx  model is:  0.9587632705663097\n",
      "\n",
      "192\n",
      "fastscnn_192a0.25t2r3pp0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:07<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The mean latency in onnx  is: 0.00041414658228556314\n",
      "\n",
      "The mean iou of onnx  model is:  0.9567282269937651\n",
      "\n",
      "192\n",
      "fastscnn_192a0.125t6r2pp0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:07<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The mean latency in onnx  is: 0.0003723752498626709\n",
      "\n",
      "The mean iou of onnx  model is:  0.9491970690436565\n",
      "\n",
      "192\n",
      "fastscnn_192a0.125t4r2pp0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:07<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The mean latency in onnx  is: 0.0004194160302480062\n",
      "\n",
      "The mean iou of onnx  model is:  0.9492550469276835\n",
      "\n",
      "192\n",
      "fastscnn_192a0.125t2r2pp0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:06<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The mean latency in onnx  is: 0.00036071499188741047\n",
      "\n",
      "The mean iou of onnx  model is:  0.947602723976583\n",
      "\n",
      "192\n",
      "fastscnn_192a0.125t2r1pp0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:06<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The mean latency in onnx  is: 0.0003138120969136556\n",
      "\n",
      "The mean iou of onnx  model is:  0.9275273251602941\n",
      "\n",
      "160\n",
      "fastscnn_160a1.0t6r1pp0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:07<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The mean latency in onnx  is: 0.0006163454055786133\n",
      "\n",
      "The mean iou of onnx  model is:  0.9620578472871891\n",
      "\n",
      "160\n",
      "fastscnn_160a0.25t6r3pp0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:07<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The mean latency in onnx  is: 0.000383908748626709\n",
      "\n",
      "The mean iou of onnx  model is:  0.9455540515010621\n",
      "\n",
      "160\n",
      "fastscnn_160a0.25t6r1pp0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:07<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The mean latency in onnx  is: 0.0002822089195251465\n",
      "\n",
      "The mean iou of onnx  model is:  0.9486539477918445\n",
      "\n",
      "160\n",
      "fastscnn_160a0.25t2r3pp0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:07<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The mean latency in onnx  is: 0.0003459568818410238\n",
      "\n",
      "The mean iou of onnx  model is:  0.9471169637898125\n",
      "\n",
      "160\n",
      "fastscnn_160a0.125t6r2pp0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:07<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The mean latency in onnx  is: 0.0003113889694213867\n",
      "\n",
      "The mean iou of onnx  model is:  0.9386430290848287\n",
      "\n",
      "160\n",
      "fastscnn_160a0.125t4r2pp0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:07<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The mean latency in onnx  is: 0.0003154436747233073\n",
      "\n",
      "The mean iou of onnx  model is:  0.9327906534332698\n",
      "\n",
      "160\n",
      "fastscnn_160a0.125t2r2pp0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:07<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The mean latency in onnx  is: 0.0003254282474517822\n",
      "\n",
      "The mean iou of onnx  model is:  0.9378713402215717\n",
      "\n",
      "160\n",
      "fastscnn_160a0.125t2r1pp0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:06<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The mean latency in onnx  is: 0.00026732603708902995\n",
      "\n",
      "The mean iou of onnx  model is:  0.9317387656389067\n",
      "\n",
      "128\n",
      "fastscnn_128a1.0t6r1pp0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:06<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The mean latency in onnx  is: 0.0004241267840067546\n",
      "\n",
      "The mean iou of onnx  model is:  0.9570604626106342\n",
      "\n",
      "128\n",
      "fastscnn_128a0.25t6r3pp0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:06<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The mean latency in onnx  is: 0.00033033291498819987\n",
      "\n",
      "The mean iou of onnx  model is:  0.9435055296136242\n",
      "\n",
      "128\n",
      "fastscnn_128a0.25t6r1pp0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:06<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The mean latency in onnx  is: 0.0002386931578318278\n",
      "\n",
      "The mean iou of onnx  model is:  0.9396590017103582\n",
      "\n",
      "128\n",
      "fastscnn_128a0.25t2r3pp0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:06<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The mean latency in onnx  is: 0.0003207878271738688\n",
      "\n",
      "The mean iou of onnx  model is:  0.9431704022292567\n",
      "\n",
      "128\n",
      "fastscnn_128a0.125t6r2pp0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:07<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The mean latency in onnx  is: 0.0002564990520477295\n",
      "\n",
      "The mean iou of onnx  model is:  0.9143371017675218\n",
      "\n",
      "128\n",
      "fastscnn_128a0.125t4r2pp0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:07<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The mean latency in onnx  is: 0.0002593664328257243\n",
      "\n",
      "The mean iou of onnx  model is:  0.9255235892840941\n",
      "\n",
      "128\n",
      "fastscnn_128a0.125t2r2pp0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:07<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The mean latency in onnx  is: 0.00024846355120340983\n",
      "\n",
      "The mean iou of onnx  model is:  0.9124509733267804\n",
      "\n",
      "128\n",
      "fastscnn_128a0.125t2r1pp0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:07<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The mean latency in onnx  is: 0.0002451018492380778\n",
      "\n",
      "The mean iou of onnx  model is:  0.9300125994437352\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#this program has to load images from memory, initialize an onnx session with the pretrained and pre-exported onnx model and then\n",
    "#then it has to perform the inference on all the images in the test set and compute the latency\n",
    "#this version uses different input dimensions from one mdel to the other\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import argparse\n",
    "import numpy as np\n",
    "import onnx\n",
    "import onnxruntime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "from torchmetrics import JaccardIndex\n",
    "from statistics import mean\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "from statistics import mean\n",
    "from tqdm import tqdm\n",
    "\n",
    "c_dir = os.getcwd()\n",
    "mt_dir = os.path.dirname(c_dir)\n",
    "models_path = os.path.join(mt_dir, \"models\")\n",
    "sys.path.insert(1, models_path)\n",
    "\n",
    "batch_size = 1\n",
    "num_workers = 1\n",
    "n_runs = 10\n",
    "\n",
    "def jaccard(input, target):\n",
    "    l_input = input.astype(bool)\n",
    "    l_target = target.astype(bool)\n",
    "    intersection = np.logical_and(l_input, l_target)\n",
    "    union = np.logical_or(l_input, l_target)\n",
    "    iou = np.sum(intersection)/np.sum(union)\n",
    "    return iou\n",
    "\n",
    "class PackagesInferenceDataset(Dataset):\n",
    "    def __init__(self, images_filenames, images_directory, masks_directory, transform=None,):\n",
    "        self.images_filenames = images_filenames\n",
    "        self.images_directory = images_directory\n",
    "        self.masks_directory = masks_directory\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_filename = self.images_filenames[idx]\n",
    "        image = cv2.imread(os.path.join(self.images_directory, image_filename))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.imread(\n",
    "            os.path.join(self.masks_directory, image_filename), cv2.IMREAD_UNCHANGED,\n",
    "        )\n",
    "        mask = mask.astype(np.float32)\n",
    "        mask[mask == 0.0] = 0.0\n",
    "        mask[mask == 255.0] = 1.0\n",
    "        original_size = tuple(image.shape[:2])\n",
    "        if self.transform is not None:\n",
    "            transformed = self.transform(image=image, mask=mask)\n",
    "            image = transformed[\"image\"]\n",
    "            mask = transformed[\"mask\"]\n",
    "        return image, mask, original_size\n",
    "\n",
    "test_images_path = os.path.join(mt_dir, \"full_dataset/test/images\")\n",
    "test_label_path = os.path.join(mt_dir, \"full_dataset/test/labels\")\n",
    "test_images_filenames = [item for item in os.listdir(test_images_path) if item.endswith(\".png\")]\n",
    "\n",
    "exp_path = os.path.join(mt_dir, \"model_checkpoints/experiments/overall\")\n",
    "ckpt_path = os.path.join(exp_path, \"onnx\")\n",
    "model_names = [ item for item in os.listdir(ckpt_path) if item.endswith(\".onnx\") ]\n",
    "model_names.sort(reverse=True)\n",
    "#load onnx model\n",
    "\n",
    "for model_name in model_names:\n",
    "    if model_name[12].isdigit():\n",
    "        dim = int(model_name[9:11])\n",
    "    else:\n",
    "        dim = int(model_name[9:12])\n",
    "    print(dim)\n",
    "    test_transform = A.Compose(\n",
    "        [\n",
    "            A.Resize(dim, dim),\n",
    "            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "            ToTensorV2(),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    test_dataset = PackagesInferenceDataset(\n",
    "        images_filenames=test_images_filenames,\n",
    "        images_directory=test_images_path, \n",
    "        masks_directory=test_label_path, \n",
    "        transform=test_transform\n",
    "    )\n",
    "    \n",
    "    \n",
    "    print(model_name[:-12])\n",
    "    model_path = os.path.join(ckpt_path, model_name)\n",
    "    onnx_model = onnx.load(model_path)\n",
    "    onnx.checker.check_model(onnx_model)\n",
    "\n",
    "    #inference with onnx\n",
    "    ort_session = onnxruntime.InferenceSession(model_path)\n",
    "\n",
    "    def to_numpy(tensor):\n",
    "        return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "\n",
    "    #inference over the entire test dataset one image at a time\n",
    "    output_onnx = []\n",
    "    latency_onnx = []\n",
    "    i = 0\n",
    "    for run in tqdm(range(n_runs)):\n",
    "        for image, msk, (height, width) in test_dataset:\n",
    "            image = image.unsqueeze(0)\n",
    "            ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(image)}\n",
    "            i+=1\n",
    "            start = time.time()\n",
    "            ort_outs = ort_session.run(None, ort_inputs)\n",
    "            lat = time.time()-start\n",
    "            latency_onnx.append(lat)\n",
    "            if run == 0:\n",
    "                output_onnx.append([ort_outs, msk])\n",
    "            #print(f\"inference latency on image {i} is {lat}\")\n",
    "\n",
    "    print()\n",
    "    print(f\"The mean latency in onnx  is: {mean(latency_onnx)}\")\n",
    "\n",
    "    ious_onnx = []\n",
    "\n",
    "    for pred, g_truth in output_onnx:\n",
    "        g_truth = g_truth.numpy()\n",
    "        outs = np.array(pred)\n",
    "        outs = outs.squeeze(0) #batch size\n",
    "        outs = outs.squeeze(0) #channels\n",
    "        outs = outs.squeeze(0) # onnx output has one extra dimension\n",
    "        outs = (outs >= 0.5) * 1\n",
    "        pred = A.resize(\n",
    "            outs, height=540, width=960, interpolation=cv2.INTER_NEAREST\n",
    "        )\n",
    "        g_truth = A.resize(\n",
    "            g_truth, height=540, width=960, interpolation=cv2.INTER_NEAREST\n",
    "        )\n",
    "        ious_onnx.append(jaccard(pred, g_truth))\n",
    "\n",
    "    print()\n",
    "    print(\"The mean iou of onnx  model is: \", mean(ious_onnx))\n",
    "    del ort_session\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
